{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adverse-breath",
   "metadata": {},
   "source": [
    "## Lab 8 -- Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-vanilla",
   "metadata": {},
   "source": [
    "#### Exercise 5.4 \n",
    "\n",
    "The pseudocode for Monte Carlo ES is ine\u0000cient because, for each state– action pair, it maintains a list of all returns and repeatedly calculates their mean. It would be more effcient to use techniques similar to those explained in Section 2.4 to maintain just the mean and a count (for each state–action pair) and update them incrementally. Describe how the pseudocode would be altered to achieve this.\n",
    "\n",
    "Given $Q_{n+1}$ in Section 2.4 as:\n",
    "\n",
    "$$ \n",
    "Q_{n+1} = \\frac{1}{n}\\sum_{i=1}^n R_i \\\\\n",
    "       = \\frac{1}{n}(R_n + \\sum_{i=1}^{n-1} R_i) \\\\\n",
    "       = \\frac{1}{n}(R_n + (n-1)\\frac{1}{n-1}\\sum_{i=1}^{n-1} R_i) \\\\\n",
    "       = \\frac{1}{n}(R_n + (n-1)Q_n) \\\\\n",
    "       = \\frac{1}{n}(R_n + nQ_n -Q_n) \\\\\n",
    "       = Q_n + \\frac{1}{n}(R_n - Q_n) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-mirror",
   "metadata": {},
   "source": [
    "#### Answer: The pesudo-code for Monte Carlo ES\n",
    "\n",
    "$Q_n(S_t, A_t)$ can be calculated from $Q_{n-1}(S_t, A_t)$ only, which is the incremental approach to save memory and computational cost is O(n).\n",
    "\n",
    "$$\n",
    "    Q_n(S_t, A_t) = \\frac{1}{n}\\sum_{i=1}^n G_i (S_t, A_t) \\\\\n",
    "                  = \\frac{1}{n}(G_n(S_t, A_t) + \\sum_{i=1}^{n-1} G_i(S_t, A_t)) \\\\\n",
    "                  = \\frac{1}{n}(G_n(S_t, A_t) + (n-1)\\frac{1}{n-1}\\sum_{i=1}^{n-1} G_i(S_t, A_t)) \\\\\n",
    "                  = \\frac{1}{n}(G_n(S_t, A_t) + (n-1)Q_{n-1}(S_t, A_t)) \\\\\n",
    "                  = \\frac{1}{n}(G_n(S_t,A_t) + nQ_{n-1}(S_t, A_t) -Q_{n-1}(S_t, A_t)) \\\\\n",
    "                  = Q_{n-1}(S_t, A_t) + \\frac{1}{n}(G_n(S_t, A_t) - Q_{n-1}(S_t, A_t)) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-president",
   "metadata": {},
   "source": [
    "#### Exercise 5.5 \n",
    "\n",
    "Consider an MDP with a single nonterminal state and a single action that transitions back to the nonterminal state with probability p and transitions to the terminal state with probability 1 - p. Let the reward be +1 on all transitions, and let $\\gamma=1$. Suppose you observe one episode that lasts 10 steps, with a return of 10. What are the first-visit and every-visit estimators of the value of the nonterminal state?\n",
    "\n",
    "Answer: Since\n",
    "$$ J(s) = \\sum_{t \\in J(s)} \\rho_{t: T(t)-1} = 10 $$, while $\\rho_{t:T(t)-1} = 1$. \n",
    "\n",
    "The first vist: $v_s = 10$ and every visit: $v_s= \\frac{1}{10}\\sum_{i=1}^{10} R_i$, where $R_1=1, R_2=2, ..., R_{10}=10)$, So, $v_s = \\frac{1}{10}(1+2+3+4+5+6+7+8+9+10) = 5.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-relationship",
   "metadata": {},
   "source": [
    "#### Exercise 5.6\n",
    "\n",
    "What is the equation analogous to (5.6) for action values Q(s, a) instead of state values V (s), again given returns generated using b?\n",
    "\n",
    "Answer: \n",
    "\n",
    "Given E.q(5.6) as:\n",
    "$$\n",
    "V(s) = \\frac{\\sum_{t \\in J(s)} \\rho_{t: T(t)-1} G_t}{\\sum_{t \\in J(s)} \\rho_{t: T(t)-1}}\n",
    "$$\n",
    "\n",
    "For Q(s, a) value:\n",
    "$$\n",
    "Q(s, a) = \\frac{\\sum_{t \\in J(s,a)} \\rho_{t+1: T(t)-1} G_t}{\\sum_{t \\in J(s,a)} \\rho_{t+1: T(t)-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-climate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
